[{"content":"It was for a project during my undergrad that I grew interest for this strange programming language. It was suggested by none other than my team mate, and hardcore Rustacean Devdutt.\nRust is different from the languages I\u0026rsquo;ve been used to, like Python and JavaScript. I have tried my hands at static typed low level languages like C and C++ and in my opinion, they are easy to get started with. But Rust is not. Rust has a steep learning curve and it takes time.\nI feel that the tradeoff here is that with C/C++, though it\u0026rsquo;s easier to get started, it takes a whole lot of time and effort to write memory safe and efficient programs. But with Rust, safety and efficiency are built-in from day one. Along with Rust\u0026rsquo;s ownership concept and the compiler that enforces it, you will get used to the underlying rules. Moreover, the compiler is patient enough to explain what went wrong, and where.\nCommunity Rust is a fairly new programming language. It doesn\u0026rsquo;t have polished edges and sometimes you get stuck while learning stuff. For a beginner, a good community is a boon. Thankfully Rust has a great community.\nAt the very beginning you have the most excellent Rust tutorial - The Rust Book. Well explained and goes in detail about the most useful parts of the language. The second best thing is the people who share what they\u0026rsquo;ve learnt along their journey - through blogs and youtube videos. (Yes, those 2hr long streaming sessions on youtube. Those too)\nLow level concepts Learn Rust - that\u0026rsquo;s the advice I\u0026rsquo;d give my younger self when starting my undergrad in CS. Rust is a low level language but still retains a high level syntax. The concepts remain, and there is a lot you\u0026rsquo;ll get to learn. As a CS student, it is extremely important to understand the low level working of a program and concepts like memory management, concurrency and the like.\nYou can build systems software projects like CLIs, operating systems, game engines, embedded system software or even web servers. My first systems software prorject was a simple shell with a few builtins. It was written in C. See vsh. I learnt about how a shell works, and how inputs and outputs are processed.\nAnother one is timers which is written in Rust and has better program design. One of the main problems I\u0026rsquo;ve faced with this is the time drift due to task switch from the CPU. The initial implementation relied on manually keeping track of each second passed by incrementing a counter.\nI\u0026rsquo;ve been learning about async rust and that itself has led me down a rabbit hole about how a runtime and the underlying operating system manages memory. I got exposed to hands on experience with Linux system calls and such. More on that in another post. Rust has certainly opened me up to a lot of low level concepts during my journey. Combined with my point above on community, the learning part is fun.\nType System Coming from a dynamic programming language like Python, facing the type system was a challenge. I had to keep track of what types my data had, and when I passed it around in my code. But now after working on a few projects, I\u0026rsquo;ve come to like it. It provides more control over how I use and pass memory. It also gives a clear structure to the data representations. The Rust compiler has been very helpful by pointing out errors and possible solutions.\nCompiler The compiler is helpful and strict at the same time. I should admit that the compiler is a bit slow but that is bearable when compared to the advantages it provides. Apart from the safety promises and performance optimizations, the error messages are articulate and the solutions are straight forward. There is a lot to learn just from the compiler itself.\nThis is my experience exploring the language till now. It has been a fun journey and I plan to continue down this lane. I wouldn\u0026rsquo;t have given this a shot if it wasn\u0026rsquo;t for my hardcore fellow Rustacean Devdutt. Hopefully, you\u0026rsquo;ll get to hear more of this!\n","permalink":"https://123vivekr.github.io/posts/2022-02-08-rust-first_impressions/","summary":"It was for a project during my undergrad that I grew interest for this strange programming language. It was suggested by none other than my team mate, and hardcore Rustacean Devdutt.\nRust is different from the languages I\u0026rsquo;ve been used to, like Python and JavaScript. I have tried my hands at static typed low level languages like C and C++ and in my opinion, they are easy to get started with.","title":"Rust: First Impressions"},{"content":"This post is a summary of the work that has been completed during the GSoC 2020 period for my project, Object Tracking. The project consisted of implementing an Object Tracking UI in Pitivi and the associated tracking functionality in GStreamer.\ncvtracker GStreamer element flatpak: add opencv_contrib\nI began by adding the opencv_contrib module to the opencv installation for the Pitivi development environment. opencv_contrib contains the library with the tracking algorithms.\nOpenCV Tracker Element for Object Tracking\nThis merge request introduces the tracking functionality in the gst-plugins-bad package.\nPreviously the opencv plugin was not being built due to the unavailability of the headers. This patch fixes the problem, ensuring that the headers are detected for the correct version of opencv and the plugin is built.\nIn the next commit: opencv: add cvtracker plugin, I implement the cvtracker element as part of the opencv GStreamer plugin and set up the associated tests to ensure correct working. The next commit: meson: add opencv/tracking header requirement ensures that the tracking library is available before building the plugin.\nI implemented an additional feature to draw a rectangle over the tracked object. This will come in handy during the testing phase and for live tracking in Pitivi. opencv: cvtracker: add draw property\nA brief explanation of the cvtracker element can be found on my blog post: cvtracker: OpenCV object tracking plugin\nTracker Perspective With the GStreamer element for tracking completed, the next stage was to implement a user-friendly UI for object tracking. The new Tracker Perspective replaces Pitivi\u0026rsquo;s main window, allowing to select an object on the viewer and track it. If the chosen tracking algorithm fails to track the object correctly, the tracking can be redone from a corrected position.\nThe work done on the Pitivi side currently resides in the Merge Request\nA brief explanation of tracking objects can be found on my blog post:\nPitivi: Object Tracking\nAs the project progressed, we iterated and made a lot of UI improvements. A demo with the explanation can be found here: Pitivi: Edit Object Tracking\n  Screenshot of the TrackerPerspective UI   Selecting an object from the viewer   Live tracking in TrackerPerspective  Processing the tracked objects   `Cover Object` button to add effects and track objects   Cover Object Popover   Cover effect on clip  A tracked object can be covered with a colored rectangle on a clip in the timeline. This can be done easily through the \u0026ldquo;Cover Object\u0026rdquo; button in the \u0026ldquo;Clip Properties\u0026rdquo; middle pane shown when a clip is selected.\n When an Asset from the Media Library is dragged and dropped on the timeline, it becomes a Clip. A user can create multiple Clips from a single Asset.\nThe tracked objects belong to the Asset. That means if an object is tracked, it’s available to all the Clips backed by the particular Asset. The tracked data is then applied to the properties of an Effect applied to the Clip to obtain the ‘cover rectangle’. Clips can have object effects independent of each other.\nIf a tracked object is deleted from the Assed in the TrackerPerspective, the effects associated with that object will be deleted from all the Clips of that Asset. The below figure shows the situation when ‘Object 2’ is deleted.\n Technical Note: Taking advantage of Assets being MetaContainers, we store the Objects\u0026rsquo;s tracking data as a pitivi::tracker_data metadata item. The tracking data is saved in the Project\u0026rsquo;s .xges file by GES when the Project is saved.\nProject Status The tracker element and Pitivi UI are complete, as demonstrated in my blog posts. However, there are 2 major bugs in the feature for adding effects to the tracked objects.\nThe first bug is when the user adds the effect for two objects, one with more tracking data than the other, the video track of the clip gets disfigured. This might be due to no available tracking data before the start, which causes the tracking box (red box in this case) to be shown at the bottom-right corner until it receives its first tracking data point. Here’s a small demo of the bug: YouTube\nThe fix for this bug is to add a zorder property to the gescompositor element of the effect and to set the tracking data point to some random far away point before the beginning of the actual tracked data points.\nThe second bug is when the user adds the effect for an object and then resizes the clip in the viewer, the effect doesn’t follow. Here’s a demo for the bug: YouTube\nThe currently discussed solution is to re-adjust the tracking data every time the user makes a change to the clip video track in the viewer, by resetting the ControlSource.\n","permalink":"https://123vivekr.github.io/posts/2020-08-29-pitivi-gsoc-work-product/","summary":"This post is a summary of the work that has been completed during the GSoC 2020 period for my project, Object Tracking. The project consisted of implementing an Object Tracking UI in Pitivi and the associated tracking functionality in GStreamer.\ncvtracker GStreamer element flatpak: add opencv_contrib\nI began by adding the opencv_contrib module to the opencv installation for the Pitivi development environment. opencv_contrib contains the library with the tracking algorithms.","title":"GSoC 2020: A summary"},{"content":"My last post was about adding a feature to track objects. But sometimes the algorithm doesn\u0026rsquo;t track the object 100% correct, so in this post, I present to you a new update which lets the user edit the tracked data easily in the Pitivi Tracker Perspective itself.\nDemo See the feature in action. YouTube\nIn the video, the user selects a clip and goes to the Tracker Perspective, by clicking on the \u0026ldquo;Track Object\u0026rdquo; button. Now, the user selects the object to track and chooses the algorithm before tracking. Pitivi tracks the object for the rest of the clip.\nBut wait, the user has accidentally chosen only a portion of the object. They can correct this by seeking to a point in the tracking and selecting the object again, this time, they get it right :) After the tracking is completed, the tracking data is updated to accomodate the updated tracking co-ordinates.\nSimilarly, we can correct faults in the tracking.\nUI improvements   Cursor changes to crosshair when hovering on the viewer   Track Object button is inside Blur Object popover   Start position of the tracked object shown as a marker on the seekbar   Added an infobar to show instructions   Info bar disappears on choosing an object  Further developments A feature to add an effect to the tracked objects is in the development stage. The tracked objects will be shown in the \u0026ldquo;Blur Object\u0026rdquo; popover. The user can add an effect by clicking on the object. More on that in another post. :)\n","permalink":"https://123vivekr.github.io/posts/2020-08-16-pitivi-object_track_editing/","summary":"My last post was about adding a feature to track objects. But sometimes the algorithm doesn\u0026rsquo;t track the object 100% correct, so in this post, I present to you a new update which lets the user edit the tracked data easily in the Pitivi Tracker Perspective itself.\nDemo See the feature in action. YouTube\nIn the video, the user selects a clip and goes to the Tracker Perspective, by clicking on the \u0026ldquo;Track Object\u0026rdquo; button.","title":"Tracking adjustments in Pitivi"},{"content":"I’ve been selected as a student developer at Pitivi for Google Summer of Code 2020. My project is to create an object tracking and blurring feature.\nThe tracking is done by passing the video clip through a pipeline which includes a tracker plugin. So, the first goal of the project was to implement the tracker plugin in GStreamer.\nIntroducing cvtracker This is a GStreamer plugin which allows the user to select an object in the initial frame of a clip by specifying the object’s bounding box (x, y, width and height coordinates). The element then tracks the object during the subsequent frames of the clip.\nThis plugin is in the gst-plugins-bad module. It is currently a merge request.\nThe plugin can be used by anyone by just installing the module. An example pipeline is given below.\nExample A sample pipeline with cvtracker looks like this:\ngst-launch-1.0 filesrc location=t.mp4 ! decodebin ! videoconvert ! cvtracker object-initial-x=175 object-initial-y=40object-initial-width=300 object-initial-height=150 algorithm=1 ! videoconvert ! xvimagesink Here’s a demo of the pipeline given above: YouTube\nAlgorithm The tracker incorporates OpenCV’s long term tracker cv::Tracker.\nThe available tracking algorithms are:\nBoosting - the Boosting tracker CSRT - the CSRT tracker KCF - the KCF (Kernelized Correlation Filter) tracker MedianFlow - the Median Flow tracker MIL - the MIL tracker MOSSE - the MOSSE (Minimum Output Sum of Squared Error) tracker TLD - the TLD (Tracking, learning and detection) tracker You might wonder why we missed the GOTURN algorithm. It was skipped due to the added complexity of setting up the models by the user.\nProperties algorithm - the tracking algorithm to use draw-rect - to draw a rectangle around the tracked object object-initial-x - object’s initial x coordinate object-initial-x - object’s initial y coordinate object-initial-height - object’s initial height object-initial-width - object’s initial width The element sends out the tracked object’s bounding box’s x, y, width and height coordinates through the pipeline bus and also through the buffer. If you want live tracking during the playback, you could use the draw-rect property.\n","permalink":"https://123vivekr.github.io/posts/2020-07-28-gstreamer-cvtracker/","summary":"I’ve been selected as a student developer at Pitivi for Google Summer of Code 2020. My project is to create an object tracking and blurring feature.\nThe tracking is done by passing the video clip through a pipeline which includes a tracker plugin. So, the first goal of the project was to implement the tracker plugin in GStreamer.\nIntroducing cvtracker This is a GStreamer plugin which allows the user to select an object in the initial frame of a clip by specifying the object’s bounding box (x, y, width and height coordinates).","title":"cvtracker: An object tracking plugin for GStreamer"},{"content":"I’ve been selected as a student developer at Pitivi for Google Summer of Code 2020. My project is to create an object tracking and blurring feature.\nIn this post, I introduce a feature in development which allows the user to track an object inside a video clip.\nObject tracking in action Before diving into the aspects, let’s see it in action. YouTube\nIn the video, the user selects the clip to be used and clicks on the “Track object” button. In the next screen (tracker perspective), the user chooses a frame and selects the object to be tracked using a drag-and-drop motion. The user then sets the tracking algorithm and initiates the tracking. Live tracking is displayed. The tracked object appears on the left pane. The user has the option to delete the tracked object.\nInternals The cvtracker is a plugin from gst-plugins-bad project (which is also a part of my GSoC project). It allows us to track the object by running the clip through a pipeline. The tracking data is available through the bus and buffer metadata.\nThe tracking in pitivi is implemented using a pipeline, which runs the clip and feeds it to the cvtracker. We extract the region-of-interest (ROI) data from the buffer.\nAn Object Manager class stores all the tracked objects in a clip. Technically, the object data is saved to the asset metadata. So every clip that gets generated using the asset has access to all the tracked objects.\nTracking data For receiving the tracking data from the cvtracker, we use fakesink with the properties: fakesink name=sink signal-handoffs=TRUE.\nThen we connect the handoff signal to the callback function:\ndef __tracker_handoff_cb(self, unused_element, buffer, unused_pad, roi_data):  video_roi = GstVideo.buffer_get_video_region_of_interest_meta_id(buffer, 0)  if video_roi:  roi_data[buffer.pts] = (video_roi.x, video_roi.y, video_roi.w, video_roi.h)  else:  self.log(\u0026#34;lost tracker at: %s\u0026#34; + str(buffer.pts / Gst.SECOND)) Further developments There’s more coming! Sometimes the tracking can be a little inaccurate, so we’re working on a feature to adjust the tracking of an object. Basically the user can manually adjust the tracking data using a simple and user friendly interface, integrated right into the tracker perspective. More on that in another post.\n","permalink":"https://123vivekr.github.io/posts/2020-07-28-pitivi-object_tracking/","summary":"I’ve been selected as a student developer at Pitivi for Google Summer of Code 2020. My project is to create an object tracking and blurring feature.\nIn this post, I introduce a feature in development which allows the user to track an object inside a video clip.\nObject tracking in action Before diving into the aspects, let’s see it in action. YouTube\nIn the video, the user selects the clip to be used and clicks on the “Track object” button.","title":"Pitivi can now track objects"},{"content":"I am Vivek and I build stuff.\nPrimarily a software engineer interested in web, linux, system design and machine learning. Here I\u0026rsquo;ll be documenting my software development journey along with a myraid of other things which I\u0026rsquo;m deeply interested in.\nIf you find my work interesting, do feel free to contact me on one of my social media platforms. I\u0026rsquo;m most active on my twitter.\n","permalink":"https://123vivekr.github.io/about/","summary":"I am Vivek and I build stuff.\nPrimarily a software engineer interested in web, linux, system design and machine learning. Here I\u0026rsquo;ll be documenting my software development journey along with a myraid of other things which I\u0026rsquo;m deeply interested in.\nIf you find my work interesting, do feel free to contact me on one of my social media platforms. I\u0026rsquo;m most active on my twitter.","title":"Welcome to my blog!"}]